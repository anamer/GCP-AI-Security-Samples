{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijGzTHJJUCPY"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VK1Q5ZYdVL4Y"
   },
   "source": [
    "## Overview\n",
    "\n",
    "### Protecting Gen AI Applications from Data Leakage\n",
    "Large language models (LLMs) are deep learning models trained on massive datasets of text. LLMs can translate language, summarize text, generate creative writing, generate code, power chatbots and virtual assistants, and complement search engines and recommendation systems.\n",
    "\n",
    "\n",
    "When incorporating your own data into generative AI applications especially via [Model Tuning](https://cloud.google.com/vertex-ai/docs/generative-ai/models/tune-models) it's possible to return a prediction with data from your dataset. In this case many organizations may want to filter LLM responses for sensitive data.\n",
    "\n",
    "\n",
    "By using Sensitive Data Protection(Cloud DLP) we can identify and take corrective action on sensitive data within LLM responses in real time.\n",
    "\n",
    "\n",
    "### Using Sensitive Data Protection(Cloud DLP) to filter LLM Responses\n",
    "\n",
    "[Sensitive Data Protection(Cloud DLP)](https://cloud.google.com/dlp) is a fully managed service designed to discover, classify, and protect your sensitive data, where it resides from databases, text-based content, or even images. It uses a variety of methods to identify sensitive data, including regular expressions, dictionaries, and contextual elements. Once sensitive data is identified, Sensitive Data Protection(Cloud DLP) can take several actions to either classify it, mask it, encrypt it or even delete it.\n",
    "\n",
    "\n",
    "Sensitive Data Protection(Cloud DLP) can be accessed via Cloud Console and used to scan data within Cloud Storage, BigQuery and other Google Cloud services. The following notebook demonstrates using it through the SDK to incorporate Sensitive Data Protection(Cloud DLP) capabilities directly into you Generative AI enabled applications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQT500QqVPIb"
   },
   "source": [
    "### Objectives\n",
    "\n",
    "In this tutorial, you will learn how to use Sensitive Data Protection(Cloud DLP) API with the Python SDK and explore how to identify and redact sensitive data within a response from PaLM 2 LLM\n",
    "\n",
    "By the end of the notebook, you should be able to understand various configurations of Sensitive Data Protection(Cloud DLP) like `inspect_config`, `deidentify_config`, `item`, and what each variable controls.\n",
    "\n",
    "The steps performed include:\n",
    "\n",
    "- Installing the Python SDKs\n",
    "- Understand a Data Leakage scenario\n",
    "  - Text generation model with `text-bison@001`\n",
    "    - Understanding prompt manipulation to return sensitive data\n",
    "- Understand Data Leakage Mitigations\n",
    "  - Using Sensitive Data Protection(Cloud DLP) with `text-bison@001` responses\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCgai1I3uriY"
   },
   "source": [
    "### Costs\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "* Vertex AI Generative AI Studio\n",
    "* Sensitive Data Protection(Cloud DLP)\n",
    "\n",
    "Learn about pricing for [Vertex AI](https://cloud.google.com/vertex-ai/pricing), and\n",
    " [Sensitive Data Protection(Cloud DLP)](https://cloud.google.com/dlp/pricing). Use the [Pricing Calculator](https://cloud.google.com/products/calculator/)\n",
    "to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mr5Btx-vwLtr"
   },
   "source": [
    "### Data governance and security\n",
    "For more information, see the documentation on [Data Governance and Generative AI](https://cloud.google.com/vertex-ai/docs/generative-ai/data-governance) on Google Cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ruKp1yOwN3Z"
   },
   "source": [
    "### Responsible AI\n",
    "Large language models (LLMs) can translate language, summarize text, generate creative writing, generate code, power chatbots and virtual assistants, and complement search engines and recommendation systems. At the same time, as an early-stage technology, its evolving capabilities and uses create potential for misapplication, misuse, and unintended or unforeseen consequences. Large language models can generate output that you don't expect, including text that's offensive, insensitive, or factually incorrect.\n",
    "\n",
    "What's more, the incredible versatility of LLMs is also what makes it difficult to predict exactly what kinds of unintended or unforeseen outputs they might produce. Given these risks and complexities, the PaLM API is designed with [Google's AI Principles](https://ai.google/principles/) in mind. However, it is important for developers to understand and test their models to deploy safely and responsibly. To aid developers, the Generative AI Studio has built-in content filtering, and the PaLM API has safety attribute scoring to help customers test Google's safety filters and define confidence thresholds that are right for their use case and business. Please refer to the [Safety filters and attributes](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/responsible-ai#safety_filters_and_attributes) section to learn more.\n",
    "\n",
    "When the PaLM API is integrated into a customer's unique use case and context, additional responsible AI considerations and [PaLM limitations](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/responsible-ai#palm_limitations) may need to be considered. We encourage customers to leverage fairness, interpretability, privacy and security [recommended practices](https://ai.google/responsibilities/responsible-ai-practices/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDU0XJ1xRDlL"
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vfBCOT7dduP4",
    "outputId": "c8ecded2-2b12-451a-857d-673a8ed5261d"
   },
   "outputs": [],
   "source": [
    "#@title Install Vertex AI and Sensitive Data Protection SDK\n",
    "# Install Google Cloud Vertex AI\n",
    "!pip install google-cloud-aiplatform --upgrade --user\n",
    "# Install DLP\n",
    "! pip install google-cloud-dlp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MkbgCJuZa1b"
   },
   "source": [
    "### If using Colab - Restart Runtime\n",
    "After installing the necessary Python SDKs you must restart the python runtime. There are a few options based on environment:\n",
    "\n",
    "**Colab**:\n",
    "1. Click the \"Restart Runtime\" button in the output of the SDK installs\n",
    "2. Click \"Runtime\" on the top toolbar -> Click \"Restart Runtime\"\n",
    "3. Run Colab Runtime Restart Code Block\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-0W3phMbcyq"
   },
   "outputs": [],
   "source": [
    "#@title Colab Runtime Restart\n",
    "#import os\n",
    "#os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy & Paste the GCP project name in the PROJECT_ID variabile bellow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "icjgvr3Wc3-J"
   },
   "outputs": [],
   "source": [
    "#@title Set Project and Location\n",
    "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "! gcloud config set project {PROJECT_ID}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticating your notebook environment\n",
    "* If you are using **Colab** to run this notebook, uncomment the cell below and continue. \n",
    "* If you are using **Vertex AI Worknebch** you can skip the next step (authenticate_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Fom0ZkMSBW6"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Used for Colab, skipped if running on Vertex-AI Workbench\n",
    "#from google.colab import auth\n",
    "#auth.authenticate_user(project_id=PROJECT_ID)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNddz_RZTa7C"
   },
   "source": [
    "### Set Model for Prediction/Generation (text-bison@001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the TextGenerationModel library, this library is a part of the Vertex AI SDK for Python. It provides a simple way to interact with the text generation capabilities of large language models hosted on GCP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4zjV4alsiVql"
   },
   "outputs": [],
   "source": [
    "from vertexai.preview.language_models import (TextGenerationModel)\n",
    "\n",
    "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ky6waJlQTFTd"
   },
   "source": [
    "## Understanding and Mitigating Data Leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ask a naive questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J43BzEhlzYML",
    "outputId": "a4061b04-2db2-470d-f369-6a4d8ac5a197"
   },
   "outputs": [],
   "source": [
    "#@title Threat Use Case: Extract Sensitive Data & Data Leakage Scenario\n",
    "\n",
    "prompt = f\"\"\"Who is the CEO of Google? What is their email?\n",
    "  \"\"\"\n",
    "response = generation_model.predict(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to block any PII data in the prompt response, to do so we will use Google Cloud __[Senstive Data Protection (SDP)] (https://cloud.google.com/security/products/dlp)__, a.k.a known as DLP. \n",
    "Sensitive Data Protection is a suite of services designed to help you discover, classify, and protect sensitive data within your GCP environment and beyond. It provides tools and capabilities to manage data risks and meet compliance requirements.\n",
    "\n",
    "Key Uses of Sensitive Data Protection:\n",
    "\n",
    "Data Discovery and Classification:\n",
    "\n",
    "> It helps identify sensitive data like personally identifiable information (PII), financial data, or intellectual property across various GCP services (BigQuery, Cloud Storage, Datastore).\n",
    "\n",
    "> It uses predefined and customizable data patterns (InfoTypes) to recognize different types of sensitive information.\n",
    "\n",
    "Data Risk Analysis:\n",
    "\n",
    "> Sensitive Data Protection integrates with Security Command Center to provide a comprehensive view of data risks by considering vulnerabilities, threat exposure, and the sensitivity of the data.\n",
    "\n",
    "> It enables you to prioritize security efforts based on the potential impact of data breaches.\n",
    "\n",
    "Data De-identification:\n",
    "\n",
    "> It offers de-identification techniques like masking, tokenization, and bucketing to protect sensitive data while preserving its utility for analysis or processing.\n",
    "\n",
    "> This allows you to share or use data without exposing sensitive details.\n",
    "\n",
    "Data Loss Prevention (DLP):\n",
    "\n",
    "> Sensitive Data Protection includes Cloud DLP, which enables real-time scanning of data in motion or at rest to detect and prevent unauthorized access or exfiltration.\n",
    "\n",
    "> You can define policies to automatically redact or block sensitive information.\n",
    "\n",
    "**InfoTypes** are predefined or custom categories that define specific types of sensitive information. They act as identifiers for the types of data that the service should look for and potentially protect. More details about InfoTypes [here] (https://cloud.google.com/sensitive-data-protection/docs/concepts-infotypes).\n",
    "\n",
    "In the example below we will use two InfoTypes: \"PERSON_NAME\" and \"EMAIL_ADDRESS\", list of all supported InfoTypes are avaliable [here] (https://cloud.google.com/sensitive-data-protection/docs/infotypes-reference), SDP users can also create [custom InfoTypes] (https://cloud.google.com/sensitive-data-protection/docs/creating-custom-infotypes).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vINTmTN4D4C9",
    "outputId": "eeef509d-8d9d-4ced-ce19-ea385cf024c0"
   },
   "outputs": [],
   "source": [
    "#@title Inspect and Redact PaLM 2 output with Sensitive Data Protection(Cloud DLP)\n",
    "\n",
    "import google.cloud.dlp  # noqa: F811, E402\n",
    "from typing import List  # noqa: F811, E402\n",
    "\n",
    "def deidentify_with_replace_infotype(\n",
    "    project: str, item: str, info_types: List[str]\n",
    ") -> None:\n",
    "    \"\"\"Uses the Data Loss Prevention API to deidentify sensitive data in a\n",
    "    string by replacing it with the info type.\n",
    "    Args:\n",
    "        project: The Google Cloud project id to use as a parent resource.\n",
    "        item: The string to deidentify (will be treated as text).\n",
    "        info_types: A list of strings representing info types to look for.\n",
    "            A full list of info type categories can be fetched from the API.\n",
    "    Returns:\n",
    "        None; the response from the API is printed to the terminal.\n",
    "    \"\"\"\n",
    "\n",
    "    # Instantiate a client\n",
    "    dlp = google.cloud.dlp_v2.DlpServiceClient()\n",
    "\n",
    "    # Convert the project id into a full resource id.\n",
    "    parent = f\"projects/{PROJECT_ID}\"\n",
    "\n",
    "    # Construct inspect configuration dictionary\n",
    "    inspect_config = {\"info_types\": [{\"name\": info_type} for info_type in info_types]}\n",
    "\n",
    "    # Construct deidentify configuration dictionary\n",
    "    deidentify_config = {\n",
    "        \"info_type_transformations\": {\n",
    "            \"transformations\": [\n",
    "                {\"primitive_transformation\": {\"replace_with_info_type_config\": {}}}\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Call the API\n",
    "    response = dlp.deidentify_content(\n",
    "        request={\n",
    "            \"parent\": parent,\n",
    "            \"deidentify_config\": deidentify_config,\n",
    "            \"inspect_config\": inspect_config,\n",
    "            \"item\": {\"value\": item},\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Print out the results.\n",
    "    print(response.item.value)\n",
    "\n",
    "deidentify_with_replace_infotype(PROJECT_ID, response.text, [\"PERSON_NAME\",\"EMAIL_ADDRESS\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sensitive content in the output was de-identified by replacing the sensitive data with the type of data, e.g.: EMAIL. SDP supports multiple transformation options, such as reduction, masking and more, [this page] (https://cloud.google.com/sensitive-data-protection/docs/transformations-reference) lists all available transformation options. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Challenge:\n",
    "\n",
    "In some cases, a country when used to reference someone's place of birth, residence, or citizenship is considered senstive information.\n",
    "Given the prompt below, mask the country name.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Which nation is Albert Einstein's birthplace?\n",
    "  \"\"\"\n",
    "response = generation_model.predict(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Ldoma_ZahRc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
