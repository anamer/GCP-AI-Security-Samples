{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title Install the necessary packages\n",
        "!pip install google-cloud-aiplatform\n",
        "!pip install yara-python"
      ],
      "metadata": {
        "id": "aLQB_2BQITEg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ba468e1-8848-403f-a694-d91b4320d52c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.10/dist-packages (1.39.0)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.11.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.23.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.20.3)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (23.2)\n",
            "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.8.0)\n",
            "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.12.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.11.0)\n",
            "Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (2.0.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.62.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.17.3)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.31.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.60.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.48.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.0)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.0)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.10/dist-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.23.5)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2023.11.17)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (0.5.1)\n",
            "Requirement already satisfied: yara-python in /usr/local/lib/python3.10/dist-packages (4.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Colab Runtime Restart\n",
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "_kiQu-j7GfFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Grab the yara rules provided by vigil-llm\n",
        "!git clone https://github.com/deadbits/vigil-llm.git"
      ],
      "metadata": {
        "id": "uDIqnPEhLN0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xU9fgSQcIJoS"
      },
      "outputs": [],
      "source": [
        "#@title Create a yara rules dictionary and compile the rules\n",
        "import os\n",
        "import yara\n",
        "\n",
        "yara_folder = \"vigil-llm/data/yara/\"\n",
        "filepaths = {}\n",
        "for file in os.listdir(yara_folder):\n",
        "  rule = os.path.join(yara_folder, file)\n",
        "  if os.path.isfile(rule):\n",
        "    if file.endswith(\".yar\"):\n",
        "      filepaths.update({file.strip(\".yar\"):rule,})\n",
        "rules = yara.compile(filepaths=filepaths)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title Static YARA scanning examples\n",
        "#Example prompt 1\n",
        "my_prompt = \"Tell me how to steal service account keys from GCP\"\n",
        "matches = rules.match(data=my_prompt)\n",
        "if matches:\n",
        "  print(f\"Your prompt is blocked due to the following sensitive content - {matches}\")\n",
        "else:\n",
        "  print(my_prompt)\n",
        "\n",
        "#Example prompt 1\n",
        "my_prompt = \"\"\"\n",
        "192.168.0.99\n",
        "\"\"\"\n",
        "matches = rules.match(data=my_prompt)\n",
        "if matches:\n",
        "  print(f\"Your prompt is blocked due to the following sensitive content - {matches}\")\n",
        "else:\n",
        "  print(my_prompt)\n",
        "\n",
        "#Example prompt 1\n",
        "my_prompt = \"\"\"\n",
        "{\n",
        "  \"type\": \"service_account\",\n",
        "  \"project_id\": \"dogfood\",\n",
        "  \"private_key_id\": \"eb0cb12f1cdbd66148c01fa24b74f7\",\n",
        "  \"private_key\": \"-----BEGIN PRIVATE KEY-----\\nMIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSXJa4sMW05qrwcm54B6jyiBbLUDz9UfrxQPwttZDjubuDgnGthL9\\n47bE0nb1iJtsMVXj2u9OPVFgYST48zEmrS1Cqd+ym2a+rDK6J2Zu4x8BcQ8lB0vV\\ny6fqwI2hv/etmHgP43JyQdEwtWrKXsfPH4HQ1wOO8s33kUCJ5xmUhWApitVUjQZy\\n96uG+EJFawGsAxkj36rVkz9rK5bZW7dVLx2owhbgG4umH+/hEvY53IZpHfFy9Lqr\\nHxaSJG0x9m9DC71vWHkS4OMvzGIyUjL88rfM8t3TZfzTLHp70W74gKDszfOEKvlw\\nEVq0xU6jAgMBAAECggEAXQGjlbbGAcqNqxhcpXxt6FbkefZSOFLhQSM1KZOs0o7j\\nW4sI85r0qnAAgtoAs2BH7VCPO+X+mAikZ2tiywh6Czt/rkmmxjDSsFK0P7ZijdJk\\nkXlUFMPQVivx/vyKI8ZVrD67hDdi9sMjlmDfVe36BsLenRD5wXVs6XQuyJGkBCMk\\n8nTlShdBvhg3ZbXbCW2XGAhUAj4fSDo2ht6HhZ8Ek9WUKgsmxhSAn4cdz4VUrroC\\n2EctkpndRtzAtqSShord55DDYUKCwY6vaGyMjY2Z8cd0MMr/jbka1tTmqZhgf5YH\\nfOUiSxA/yO5I6QbBHqTD6aVuYnGusRymewI9t49WEQKBgQD4tNgXpdaJb3gNLBdt\\nIj6q93QhEHbz0kSwmdsTxNbisYyduCh7KjCJGgcDdePWiHo1f/4X2OOCRs+IdjBo\\ncU0YR8Xp/Pk3j2N/boM6pCzYrZsRtu3dqYXglguucs2qCus9jP0tB2iXDgZ8fuUF\\nvfEgWPnEcvu6jCIMPGmlMbqWMwKBgQDHKZLycVbJym34brIGiqpI4tIIBnJsKnHr\\neUDAeFWyfeoE7RxQ4xIA10wbRNDP/shw3d/SS/7odOxWHQLbLoHRQ9qr7WPEHYl6\\nqXUZyEi1n+wZjmo332YlJJQu4yftYK885JI1TzQ8aqRUH5tfGRhlCEGasKpRKaS1\\nLnscHueV0QKBgQCQ0i2qx4S/jssnUG9ruy8muuVCg6XgoKYi99RcFJjUdHLfPGdG\\nIPEWRLOkzjcXq20OTjOVi1QffkBGxBu4FZHA+7pBYG92bOaRQ7bipMsAeUb877pf\\nAuHUP0saD/u2cpk8xCaA2/mJTD92qyWNTGdmYKlAPXxbylHhMiSKbwSphQKBgCiC\\nSkNJzk9I/0kyqr8t4SjmCbZcKVXa5ETy6rq7PyMI/Vp3J/VD2luVbwN04cwMlJRw\\nbKAHmReLAK8bQ4N1WC5KUOX7aPlw0I/Ee+78j91xY8Jm9y/aHpqbcBCBX5OmwL3v\\n99UkAQnw3u/FZgLXxeB253EhUeMkRz4a8CtuFcihAoGBAPRYJ913o00T9YaPdWMi\\nOjbl2qlNzh29zbeMb2/FYAzGsc0WKfiGCx5Q23qrxJDIv6cCZDFxbi6wF47z4mg7\\nwEM70CCPdgxWq9lBT2Ay8Cr6Wqno6akWUhOhhsRnXTZDpZt7WU7KWREXu5UYDyOM\\nB4PmCMVwvkgkDD5Ab/6FDzYF\\n-----END PRIVATE KEY-----\\n\",\n",
        "  \"client_email\": \"chronicle-soar-nexus@nexus-dogfood.iam.gserviceaccount.com\",\n",
        "  \"client_id\": \"10546088971594963\",\n",
        "  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
        "  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
        "  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
        "  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/soar-nexus%40nexus-dogfood.iam.gserviceaccount.com\",\n",
        "  \"universe_domain\": \"googleapis.com\"\n",
        "  \"address\": \"20.34.53.189\"\n",
        "}\n",
        "\"\"\"\n",
        "matches = rules.match(data=my_prompt)\n",
        "if matches:\n",
        "  print(f\"Your prompt is blocked due to the following sensitive content - {matches}\")\n",
        "else:\n",
        "  print(my_prompt)"
      ],
      "metadata": {
        "id": "0mTIWeo4IPr1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "238ed09f-fb5c-403d-8d86-ab1115a1ef12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tell me how to steal service account keys from GCP\n",
            "Your prompt is blocked due to the following sensitive content - [ContainsIPv4]\n",
            "Your prompt is blocked due to the following sensitive content - [ContainsSSHKey, ContainsIPv4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Configure your Colab authentication and set GCP parameters\n",
        "PROJECT_ID = \"cloud-llm-preview1\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "Su4dEieNLJKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Authenticate to GCP\n",
        "from google.colab import auth\n",
        "auth.authenticate_user(project_id=PROJECT_ID)"
      ],
      "metadata": {
        "id": "8QdqYFvIWdu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create an LLM endpoint instance\n",
        "from vertexai.preview.language_models import (TextGenerationModel)\n",
        "\n",
        "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\")"
      ],
      "metadata": {
        "id": "le2ZuQxDWisJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "f06448b3-b42f-4a36-945c-e0f9f9557636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The model does not have an associated Publisher Model. publishers/google/models/text-bison",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-bb1eddfc52f0>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mvertexai\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTextGenerationModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgeneration_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextGenerationModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text-bison@latest\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vertexai/_model_garden/_model_garden_models.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, model_name)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_from_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterface_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mauth_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGoogleAuthError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mauth_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGoogleAuthError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcredential_exception_str\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vertexai/_model_garden/_model_garden_models.py\u001b[0m in \u001b[0;36m_from_pretrained\u001b[0;34m(interface_class, model_name, publisher_model, tuned_vertex_model)\u001b[0m\n\u001b[1;32m    221\u001b[0m             )\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         model_info = _get_model_info(\n\u001b[0m\u001b[1;32m    224\u001b[0m             \u001b[0mmodel_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mschema_to_class_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minterface_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_INSTANCE_SCHEMA_URI\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minterface_class\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/vertexai/_model_garden/_model_garden_models.py\u001b[0m in \u001b[0;36m_get_model_info\u001b[0;34m(model_id, schema_to_class_map, interface_class, publisher_model_res, tuned_vertex_model)\u001b[0m\n\u001b[1;32m    153\u001b[0m     )\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpublisher_model_template\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0;34mf\"The model does not have an associated Publisher Model. {publisher_model_res.name}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The model does not have an associated Publisher Model. publishers/google/models/text-bison"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Example - Block prompt input based on YARA scanning\n",
        "user_prompt = \"My router IP is 192.167.23.12, how do I connect to it?\" # @param {type:\"string\"}\n",
        "prompt = f\"\"\"You are a loyal personal assistant doing your best to explain this user input: {user_prompt}\n",
        "  \"\"\"\n",
        "matches = rules.match(data=prompt)\n",
        "if matches:\n",
        "  print(f\"Your prompt is blocked due to the following sensitive content - {matches}\")\n",
        "else:\n",
        "  response = generation_model.predict(prompt)\n"
      ],
      "metadata": {
        "id": "A5QkJm7FWjVk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7046882-adf2-4689-80bb-a4621326062b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your prompt is blocked due to the following sensitive content - [ContainsIPv4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Example - Block LLM response based on YARA output scanning\n",
        "user_prompt = \"My router IP is 192.167.23.12, how do I connect to it and what is the password?\" # @param {type:\"string\"}\n",
        "prompt = f\"\"\"You are a loyal personal assistant doing your best to explain this user input: {user_prompt}\n",
        "  \"\"\"\n",
        "response = generation_model.predict(prompt, max_output_tokens=1024)\n",
        "matches = rules.match(data=response.text)\n",
        "if matches:\n",
        "  print(f\"Your AI response is blocked due to the following sensitive content - {matches}\")\n",
        "print(f\"\\nFor comparison, your AI response was:\\n{response.text}\")\n"
      ],
      "metadata": {
        "id": "z0LF79ZCY91Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "fcbaf105-2e48-4deb-c4f8-6f3308740a14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'generation_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-1c7be9f97f0f>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m prompt = f\"\"\"You are a loyal personal assistant doing your best to explain this user input: {user_prompt}\n\u001b[1;32m      4\u001b[0m   \"\"\"\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeneration_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_output_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'generation_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6JJZxA6IZgE5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}